{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据收集\n",
    "2. 数据清洗\n",
    "3. 数据标注\n",
    "4. 数据增强\n",
    "5. 模型设计\n",
    "6. 模型训练\n",
    "7. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码打开摄像头\n",
    "import cv2\n",
    "# 根据摄像头id打开乐视摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    k = cv2.waitKey(10)\n",
    "    if k== ord('q'):\n",
    "        break\n",
    "    cv2.imshow(\"image\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采集stop类型的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码打开摄像头\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SAVE_PATH = './stop/'\n",
    "\n",
    "# 根据摄像头id打开乐视摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    k = cv2.waitKey(10)\n",
    "    if k== ord('q'):\n",
    "        break\n",
    "        \n",
    "    if k == 32: ## 如果按下空格键\n",
    "        save_path = os.path.join(IMG_SAVE_PATH,'{}.jpg'.format(count))\n",
    "        count +=1 \n",
    "        cv2.imwrite(save_path,frame)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame,\"collecting {}\".format(count),(5,50),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码打开摄像头\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SAVE_PATH = './go/'\n",
    "\n",
    "# 根据摄像头id打开乐视摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    k = cv2.waitKey(10)\n",
    "    if k== ord('q'):\n",
    "        break\n",
    "        \n",
    "    if k == 32: ## 如果按下空格键\n",
    "        save_path = os.path.join(IMG_SAVE_PATH,'{}.jpg'.format(count))\n",
    "        count +=1 \n",
    "        cv2.imwrite(save_path,frame)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame,\"collecting {}\".format(count),(5,50),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码打开摄像头\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SAVE_PATH = './parking/'\n",
    "\n",
    "# 根据摄像头id打开乐视摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    k = cv2.waitKey(10)\n",
    "    if k== ord('q'):\n",
    "        break\n",
    "        \n",
    "    if k == 32: ## 如果按下空格键\n",
    "        save_path = os.path.join(IMG_SAVE_PATH,'{}.jpg'.format(count))\n",
    "        count +=1 \n",
    "        cv2.imwrite(save_path,frame)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame,\"collecting {}\".format(count),(5,50),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码打开摄像头\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SAVE_PATH = './other/'\n",
    "\n",
    "# 根据摄像头id打开乐视摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    k = cv2.waitKey(10)\n",
    "    if k== ord('q'):\n",
    "        break\n",
    "        \n",
    "    if k == 32: ## 如果按下空格键\n",
    "        save_path = os.path.join(IMG_SAVE_PATH,'{}.jpg'.format(count))\n",
    "        count +=1 \n",
    "        cv2.imwrite(save_path,frame)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame,\"collecting {}\".format(count),(5,50),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "images = [] # 存储所有的照片\n",
    "labels = [] # 存储所有的标注信息  0，other  ； 1，go；2，parking；3，stop\n",
    "\n",
    "files = os.listdir('./other/') #其他\n",
    "for file in files:\n",
    "    path = os.path.join('./other',file)\n",
    "    img = cv2.imread(path)\n",
    "    ## 压缩原始图片到150*150分辨率\n",
    "    images.append(cv2.resize(img,(150,150),interpolation=cv2.INTER_AREA))\n",
    "    labels.append(0) # other的标签是0 \n",
    "    \n",
    "\n",
    "files = os.listdir('./go/') #go\n",
    "for file in files:\n",
    "    path = os.path.join('./go',file)\n",
    "    img = cv2.imread(path)\n",
    "    ## 压缩原始图片到150*150分辨率\n",
    "    images.append(cv2.resize(img,(150,150),interpolation=cv2.INTER_AREA))\n",
    "    labels.append(1) # go的标签是1\n",
    "    \n",
    "\n",
    "files = os.listdir('./parking/') #parking\n",
    "for file in files:\n",
    "    path = os.path.join('./parking',file)\n",
    "    img = cv2.imread(path)\n",
    "    ## 压缩原始图片到150*150分辨率\n",
    "    images.append(cv2.resize(img,(150,150),interpolation=cv2.INTER_AREA))\n",
    "    labels.append(2) # parking的标签是2\n",
    "\n",
    "\n",
    "files = os.listdir('./stop/') #stop\n",
    "for file in files:\n",
    "    path = os.path.join('./stop',file)\n",
    "    img = cv2.imread(path)\n",
    "    ## 压缩原始图片到150*150分辨率\n",
    "    images.append(cv2.resize(img,(150,150),interpolation=cv2.INTER_AREA))\n",
    "    labels.append(3) # parking的标签是2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共采集了804条数据，804条标签\n"
     ]
    }
   ],
   "source": [
    "print(\"一共采集了{}条数据，{}条标签\".format(len(images),len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 持久化保存训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.savez(\"images.npz\",images)\n",
    "np.savez('labels.npz',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "index = np.random.randint(len(images))\n",
    "plt.imshow(images[index])\n",
    "print(labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn模型设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Input -> Conv -> ReLU -> Pool -> Conv –> ReLU –> Pool -> FC - Output\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               313800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 338,188\n",
      "Trainable params: 338,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 构建卷积神经网络CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 第一层卷积，卷积核3x3的，卷积的数量特征提取器16个，激活函数relu\n",
    "model.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=(150,150,3))) \n",
    "\n",
    "#下采样 pooling 把图像的大小降低为原来的1/4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#第二层卷积\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "## 降维打击，把数据打平，把多个卷积后的图像，转换成一个特征向量\n",
    "model.add(Flatten())\n",
    "\n",
    "## 全连接层添加一些隐藏的神经元\n",
    "model.add(Dense(200,activation='relu'))\n",
    "\n",
    "## 输出层\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)/255.0 # 图像归一化，把0~255的像素值压缩到0~1之间\n",
    "y = np.eye(4)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "9/9 [==============================] - 6s 620ms/step - loss: 1.3917 - accuracy: 0.2687\n",
      "Epoch 2/25\n",
      "9/9 [==============================] - 6s 641ms/step - loss: 1.3184 - accuracy: 0.3893\n",
      "Epoch 3/25\n",
      "9/9 [==============================] - 6s 666ms/step - loss: 0.9504 - accuracy: 0.6741\n",
      "Epoch 4/25\n",
      "9/9 [==============================] - 6s 665ms/step - loss: 0.8845 - accuracy: 0.6642\n",
      "Epoch 5/25\n",
      "9/9 [==============================] - 6s 667ms/step - loss: 0.5489 - accuracy: 0.8694\n",
      "Epoch 6/25\n",
      "9/9 [==============================] - 6s 641ms/step - loss: 0.2981 - accuracy: 0.9055\n",
      "Epoch 7/25\n",
      "9/9 [==============================] - 6s 669ms/step - loss: 0.2331 - accuracy: 0.9353\n",
      "Epoch 8/25\n",
      "9/9 [==============================] - 6s 656ms/step - loss: 0.1695 - accuracy: 0.9478\n",
      "Epoch 9/25\n",
      "9/9 [==============================] - 6s 673ms/step - loss: 0.1457 - accuracy: 0.9565\n",
      "Epoch 10/25\n",
      "9/9 [==============================] - 6s 662ms/step - loss: 0.1203 - accuracy: 0.9701\n",
      "Epoch 11/25\n",
      "9/9 [==============================] - 6s 648ms/step - loss: 0.0908 - accuracy: 0.9739\n",
      "Epoch 12/25\n",
      "9/9 [==============================] - 6s 686ms/step - loss: 0.0660 - accuracy: 0.9789\n",
      "Epoch 13/25\n",
      "9/9 [==============================] - 6s 673ms/step - loss: 0.0750 - accuracy: 0.9701\n",
      "Epoch 14/25\n",
      "9/9 [==============================] - 6s 634ms/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 15/25\n",
      "9/9 [==============================] - 6s 653ms/step - loss: 0.0273 - accuracy: 0.9900\n",
      "Epoch 16/25\n",
      "9/9 [==============================] - 6s 697ms/step - loss: 0.0233 - accuracy: 0.9913\n",
      "Epoch 17/25\n",
      "9/9 [==============================] - 6s 623ms/step - loss: 0.0321 - accuracy: 0.9913\n",
      "Epoch 18/25\n",
      "9/9 [==============================] - 6s 638ms/step - loss: 0.0228 - accuracy: 0.9950\n",
      "Epoch 19/25\n",
      "9/9 [==============================] - 6s 643ms/step - loss: 0.0278 - accuracy: 0.9938\n",
      "Epoch 20/25\n",
      "9/9 [==============================] - 6s 640ms/step - loss: 0.0316 - accuracy: 0.9863\n",
      "Epoch 21/25\n",
      "9/9 [==============================] - 6s 669ms/step - loss: 0.0138 - accuracy: 0.9963\n",
      "Epoch 22/25\n",
      "9/9 [==============================] - 6s 643ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 23/25\n",
      "9/9 [==============================] - 6s 639ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 24/25\n",
      "9/9 [==============================] - 6s 646ms/step - loss: 0.0072 - accuracy: 0.9988\n",
      "Epoch 25/25\n",
      "9/9 [==============================] - 6s 643ms/step - loss: 0.0189 - accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2849ab18288>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,batch_size=100,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('a.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-56276636b23c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('a.h5')\n",
    "cap = cv2.VideoCapture(1)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    img = cv2.resize(frame,(150,150))\n",
    "    #预测的值\n",
    "    pred = model.predict(np.array([img/255.0]))\n",
    "    type = np.argmax(pred)    \n",
    "    str = \"\"\n",
    "    if type == 1:\n",
    "        str = \"go\"\n",
    "    elif type == 2:\n",
    "        str = \"parking\"\n",
    "    elif type == 3:\n",
    "        str = \"stop\"\n",
    "    \n",
    "    cv2.putText(frame,\"-->{}\".format(str),(5, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('itheima',frame)\n",
    "    \n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1,go ; 2,parking ; 3,stop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               313800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 338,188\n",
      "Trainable params: 338,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
    "### 引入dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "## 构建卷积神经网络CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 第一层卷积，卷积核3x3的，卷积的数量特征提取器16个，激活函数relu\n",
    "model.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=(150,150,3))) \n",
    "\n",
    "#下采样 pooling 把图像的大小降低为原来的1/4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "#第二层卷积\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "## 降维打击，把数据打平，把多个卷积后的图像，转换成一个特征向量\n",
    "model.add(Flatten())\n",
    "\n",
    "## 全连接层添加一些隐藏的神经元\n",
    "model.add(Dense(200,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## 输出层\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X,y,batch_size=1,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*在现有的数据基础上，采用图形的变换方法增加更多的样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强的工具包\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 声明一个数据增强器\n",
    "train_datagen = ImageDataGenerator(rotation_range=45,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,\n",
    "                  fill_mode='nearest',horizontal_flip=True,vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./26.jpg')\n",
    "x = img_to_array(img)\n",
    "#\n",
    "i = 0\n",
    "for batch in train_datagen.flow(np.array([x]),save_to_dir='output',save_format='jpg'):\n",
    "    i  = i +1\n",
    "    if i >100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
