{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集1100,测试集276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\tfenv\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#拆分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['center'],data['steering'],test_size =0.2 ,random_state=25)\n",
    "print(\"训练集{},测试集{}\".format(len(X_train),len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#完整的数据增强器\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "def zoom_img(img):\n",
    "    # 得到一个图像的缩放器\n",
    "    zoom = iaa.Affine(scale=(1.0,1.3))\n",
    "    return zoom.augment_image(img)\n",
    "def trans_img(img):\n",
    "    # 得到一个图像的平移器\n",
    "    trans = iaa.Affine(translate_percent={'x':(-0.1,0.1),'y':(-0.1,0.1)})\n",
    "    return trans.augment_image(img)\n",
    "def img_random_brightness(img):\n",
    "    #亮度变换的数据增强器\n",
    "    brightness = iaa.Multiply((0.3,1.2))\n",
    "    return brightness.augment_image(img)\n",
    "def img_gaussian_blur(img):\n",
    "    #高斯模糊的数据增强器\n",
    "    gaussian_blur = iaa.GaussianBlur(sigma=(0.1,3))\n",
    "    return gaussian_blur.augment_image(img)\n",
    "def img_motion_blur(img):\n",
    "    #高斯模糊的数据增强器\n",
    "    motion_blur = iaa.MotionBlur()\n",
    "    return motion_blur.augment_image(img)\n",
    "def img_flip(img,steering_angle):\n",
    "    #高斯模糊的数据增强器\n",
    "    flip = iaa.Fliplr(1.0)\n",
    "    return flip.augment_image(img),-steering_angle\n",
    "\n",
    "## 自定义组合算法， 随机的数据增强。\n",
    "## path，图片路径。 steering_angle方向盘角度\n",
    "def random_augment(path,steering_angle):\n",
    "    image = plt.imread(path)\n",
    "    if np.random.rand()<0.5:\n",
    "        image = zoom_img(image)\n",
    "    if np.random.rand()<0.5:\n",
    "        image = trans_img(image)\n",
    "    if np.random.rand()<0.5:\n",
    "        image = img_random_brightness(image)\n",
    "    if np.random.rand()<0.5:\n",
    "        image = img_gaussian_blur(image)\n",
    "    if np.random.rand()<0.5:\n",
    "        image = img_motion_blur(image)\n",
    "    if np.random.rand()<0.5:\n",
    "        image,steering_angle = img_flip(image,steering_angle)   \n",
    "    return image,steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集数据增强器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def train_batch_generator(batch_size):\n",
    "    while True:\n",
    "        batch_img = [] # 批量生成的图片\n",
    "        batch_angle = [] # 每个图片对应一个角度\n",
    "        for i in range(batch_size):\n",
    "            ## 从原始的训练集里面随机获取一张照片\n",
    "            index = np.random.randint(0,len(X_train))\n",
    "            ## 获取训练集图片的路径\n",
    "            path = X_train.iloc[index]\n",
    "            ## 获取训练集图片对应的方向盘角度\n",
    "            angle = float(y_train.iloc[index])         \n",
    "            newimg, newangle = random_augment(path,angle)\n",
    "            ## 对训练数据进行预处理\n",
    "            newimg = newimg[60:135,:,:]\n",
    "            newimg = cv2.GaussianBlur(newimg,(3,3),1)\n",
    "            newimg = cv2.resize(newimg,(200,66))\n",
    "            newimg = cv2.cvtColor(newimg,cv2.COLOR_RGB2YUV)\n",
    "            newimg = newimg/255.0\n",
    "            \n",
    "            batch_img.append(newimg)\n",
    "            batch_angle.append(newangle)\n",
    "        yield np.array(batch_img),np.array(batch_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集的数据增强器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def test_batch_generator(batch_size):\n",
    "    while True:\n",
    "        batch_img = [] # 批量生成的图片\n",
    "        batch_angle = [] # 每个图片对应一个角度\n",
    "        for i in range(batch_size):\n",
    "            ## 从原始的训练集里面随机获取一张照片\n",
    "            index = np.random.randint(0,len(X_test))\n",
    "            ## 获取训练集图片的路径\n",
    "            path = X_test.iloc[index]\n",
    "            ## 获取训练集图片对应的方向盘角度\n",
    "            angle = float(y_test.iloc[index])         \n",
    "            newimg, newangle = random_augment(path,angle)\n",
    "            ## 对训练数据进行预处理\n",
    "            newimg = newimg[60:135,:,:]\n",
    "            newimg = cv2.GaussianBlur(newimg,(3,3),1)\n",
    "            newimg = cv2.resize(newimg,(200,66))\n",
    "            newimg = cv2.cvtColor(newimg,cv2.COLOR_RGB2YUV)\n",
    "            newimg = newimg/255.0\n",
    "            \n",
    "            batch_img.append(newimg)\n",
    "            batch_angle.append(newangle)\n",
    "        yield np.array(batch_img),np.array(batch_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1164)              1342092   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1164)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,595,511\n",
      "Trainable params: 1,595,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "# 创建一个顺序模型\n",
    "model = tf.keras.Sequential()\n",
    "# normalnation后的第一层\n",
    "model.add(tf.keras.layers.Conv2D(24,(5,5),strides=(2,2),input_shape=(66,200,3),activation='elu'))\n",
    "# 第二层卷积\n",
    "model.add(tf.keras.layers.Conv2D(36,(5,5),strides=(2,2),activation='elu'))\n",
    "# 第三层卷积\n",
    "model.add(tf.keras.layers.Conv2D(48,(5,5),strides=(2,2),activation='elu'))\n",
    "# 第四层卷积\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='elu'))\n",
    "# 第五层卷积\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='elu'))\n",
    "\n",
    "# 防止训练过拟合\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# 全连接打平\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# 全连接的隐藏层\n",
    "model.add(tf.keras.layers.Dense(1164,activation='elu'))\n",
    "# 防止训练过拟合\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(100,activation='elu'))\n",
    "# 防止训练过拟合\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(50,activation='elu'))\n",
    "# 防止训练过拟合\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10,activation='elu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1)) # 方向盘的角度。\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 79s 8s/step - loss: 2.7369 - val_loss: 0.3166\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.7975 - val_loss: 0.1974\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.4167 - val_loss: 0.1062\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.3013 - val_loss: 0.1665\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.2392 - val_loss: 0.1187\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.4005 - val_loss: 0.3439\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.3524 - val_loss: 0.1358\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.1944 - val_loss: 0.1164\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.1919 - val_loss: 0.1206\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 79s 8s/step - loss: 0.1453 - val_loss: 0.1147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c754ffd5c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 编译模型,回归问题\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "## 使用数据增强器训练的话，api有细微差别\n",
    "model.fit_generator(train_batch_generator(1000),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=10,\n",
    "                   validation_data=test_batch_generator(300),\n",
    "                    validation_steps=10\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 22ms/step - loss: 0.1117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11174007505178452"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 加载上一次课的验证集的数据文件\n",
    "npzfile = np.load('X_test.npz')\n",
    "last_X_test = npzfile['arr_0']\n",
    "npzfile = np.load('y_test.npz')\n",
    "last_y_test = npzfile['arr_0']\n",
    "model.evaluate(last_X_test,last_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练的过程中，保存每次训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 8s 826ms/step - loss: 5.7208 - val_loss: 0.8426\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 9s 873ms/step - loss: 1.0882 - val_loss: 0.1336\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 8s 812ms/step - loss: 0.4498 - val_loss: 0.1246\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 9s 861ms/step - loss: 0.2809 - val_loss: 0.1177\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 9s 852ms/step - loss: 0.1757 - val_loss: 0.1478\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 8s 848ms/step - loss: 0.1403 - val_loss: 0.1428\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 8s 832ms/step - loss: 0.1454 - val_loss: 0.1182\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 8s 840ms/step - loss: 0.1206 - val_loss: 0.1206\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 0.1262 - val_loss: 0.1080\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.1237 - val_loss: 0.1051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21099829e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用一个特殊的回调，动态保存每次训练的结果\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## 编译模型,回归问题\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "checkpoint = ModelCheckpoint('{epoch:04d}.h5')\n",
    "## 使用数据增强器训练的话，api有细微差别\n",
    "model.fit_generator(train_batch_generator(100),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_batch_generator(30),\n",
    "                    validation_steps=10,\n",
    "                    callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## earlystopping技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 8s 848ms/step - loss: 2.9253 - val_loss: 0.2114\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 0.4338 - val_loss: 0.2805\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 8s 817ms/step - loss: 0.4100 - val_loss: 0.1206\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 8s 837ms/step - loss: 0.3757 - val_loss: 0.1373\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 8s 812ms/step - loss: 0.2378 - val_loss: 0.1210\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 0.2014 - val_loss: 0.0926\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 0.1453 - val_loss: 0.1094\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 0.1400 - val_loss: 0.1096\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 8s 806ms/step - loss: 0.1273 - val_loss: 0.1072\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 8s 799ms/step - loss: 0.1194 - val_loss: 0.1056\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1158Restoring model weights from the end of the best epoch.\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 0.1158 - val_loss: 0.1056\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2109a268bc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# 创建一个动态早停止技术\n",
    "# monitor监控哪个指标\n",
    "# patience 耐心指数\n",
    "# restore_best_weights 重新加载最好的权重\n",
    "earlystopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.fit_generator(train_batch_generator(100),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_batch_generator(30),\n",
    "                    validation_steps=10,\n",
    "                    callbacks=[earlystopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态学习速率技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 8s 810ms/step - loss: 0.7387 - val_loss: 0.3353\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 0.3682 - val_loss: 0.2718\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 8s 792ms/step - loss: 0.2647 - val_loss: 0.1266\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 8s 810ms/step - loss: 0.3143 - val_loss: 0.2720\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 8s 810ms/step - loss: 0.2901 - val_loss: 0.1745\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2278\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "10/10 [==============================] - 8s 817ms/step - loss: 0.2278 - val_loss: 0.1410\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 8s 844ms/step - loss: 0.1522 - val_loss: 0.1054\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 0.1447 - val_loss: 0.1063\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 8s 815ms/step - loss: 0.1361 - val_loss: 0.1135\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1408\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "10/10 [==============================] - 8s 819ms/step - loss: 0.1408 - val_loss: 0.1070\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 8s 840ms/step - loss: 0.1479 - val_loss: 0.1195\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 8s 836ms/step - loss: 0.1089 - val_loss: 0.1010\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 8s 806ms/step - loss: 0.1134 - val_loss: 0.0925\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 0.1151 - val_loss: 0.1312\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 8s 821ms/step - loss: 0.1050 - val_loss: 0.1046\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1021\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "10/10 [==============================] - 8s 831ms/step - loss: 0.1021 - val_loss: 0.1162\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 8s 849ms/step - loss: 0.1064 - val_loss: 0.1083\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 8s 847ms/step - loss: 0.1139 - val_loss: 0.1200\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1072\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "10/10 [==============================] - 9s 895ms/step - loss: 0.1072 - val_loss: 0.1180\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 8s 826ms/step - loss: 0.1023 - val_loss: 0.1117\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 8s 809ms/step - loss: 0.1169 - val_loss: 0.1344\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1122\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "10/10 [==============================] - 9s 871ms/step - loss: 0.1122 - val_loss: 0.1090\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 9s 866ms/step - loss: 0.1031 - val_loss: 0.1125\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.1281 - val_loss: 0.1282\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1076\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.1076 - val_loss: 0.1116\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 8s 836ms/step - loss: 0.1119 - val_loss: 0.0953\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 0.1093 - val_loss: 0.1237\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1084\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "10/10 [==============================] - 7s 719ms/step - loss: 0.1084 - val_loss: 0.1237\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 8s 761ms/step - loss: 0.1142 - val_loss: 0.1232\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 8s 796ms/step - loss: 0.1068 - val_loss: 0.1360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x210999b46c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,verbose=1,min_delta=0.0001)\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.fit_generator(train_batch_generator(100),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=30,\n",
    "                    validation_data=test_batch_generator(30),\n",
    "                    validation_steps=10,\n",
    "                    callbacks=[reduce_lr]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
